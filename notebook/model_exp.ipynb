{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aa2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score, recall_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ba6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('E:\\\\NAAMII\\\\Machine_learning\\\\dataset\\\\train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb63960",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6c5865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7871080a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df['CLASS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc45f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(['CLASS', 'ID'], axis=1, errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182109f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for infinite and extreme values first\n",
    "print(f\"\\nData Quality Check:\")\n",
    "inf_count = np.isinf(features.values).sum()\n",
    "nan_count = np.isnan(features.values).sum()\n",
    "print(f\"Infinite values: {inf_count}\")\n",
    "print(f\"NaN values: {nan_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d54fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace infinite values with NaN for statistics calculation\n",
    "features_clean = features.replace([np.inf, -np.inf], np.nan)\n",
    "features_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281d02b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_clean.dropna(axis=1, thresh=0.9 * len(features_clean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0b55b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute remaining NaNs with column mean\n",
    "features_clean.fillna(features_clean.mean(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4166ffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. REMOVE ZERO-VARIANCE FEATURES\n",
    "var_thresh = VarianceThreshold(threshold=0.0)\n",
    "X_var = var_thresh.fit_transform(features_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8252e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE HIGHLY CORRELATED FEATURES\n",
    "def remove_high_correlation_features(X, threshold=0.95):\n",
    "    corr_matrix = pd.DataFrame(X).corr().abs()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    return pd.DataFrame(X).drop(columns=to_drop, axis=1)\n",
    "\n",
    "X_clean = remove_high_correlation_features(X_var, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a8441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. SCALING\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_var)  # or X_clean if using correlation pruning\n",
    "\n",
    "# 6. DIMENSIONALITY REDUCTION WITH PCA (retain 95% variance)\n",
    "pca = PCA(n_components=0.9, random_state=42)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7398e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eba600",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df['CLASS']\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e497b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Helper function to calculate all metrics\n",
    "def evaluate(y_true, y_pred, y_proba):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    specificity = tn / (tn + fp)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'F1': f1_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'Specificity': specificity,\n",
    "        'AUROC': roc_auc_score(y_true, y_proba)\n",
    "    }\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(class_weight='balanced' ,random_state=42,C=0.01,l1_ratio=0.9,solver= 'saga',penalty='elasticnet'),\n",
    "    \"RandomForest\": RandomForestClassifier(class_weight='balanced', n_estimators=100, random_state=42,max_depth=None,min_samples_leaf=2, min_samples_split=5),\n",
    "    \"XGBoost\": XGBClassifier(scale_pos_weight=191/124, eval_metric='logloss', random_state=42,learing_rate=0.2, n_estimators=200, max_depth=3, subsample=0.8, colsample_bytree=0.8, use_label_encoder=False, verbosity=0),\n",
    "    \"SVM\":  SVC(kernel='linear', class_weight='balanced', probability=True, random_state=42,C= 0.001),\n",
    "    \"LightGBM\": LGBMClassifier(class_weight='balanced', random_state=42 , learning_rate=0.01, max_depth= 3, n_estimators= 200),\n",
    "    \"NaiveBayes\": GaussianNB(var_smoothing= 1e-09)\n",
    "}\n",
    "\n",
    "# Cross-validation setup\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "results = {model_name: [] for model_name in models}\n",
    "\n",
    "# Loop through models and perform cross-validation\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(X_pca, y)):\n",
    "        X_train, X_val = X_pca[train_idx], X_pca[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_proba = model.predict_proba(X_val)[:, 1]\n",
    "        \n",
    "        metrics = evaluate(y_val, y_pred, y_proba)\n",
    "        results[model_name].append(metrics)\n",
    "        print(f\" Fold {fold+1}: \" + \", \".join([f\"{k}: {v:.4f}\" for k, v in metrics.items()]))\n",
    "\n",
    "# Average results\n",
    "print(\"\\nðŸ“Š Average Cross-Validation Results:\")\n",
    "for model_name, folds in results.items():\n",
    "    avg = {k: np.mean([fold[k] for fold in folds]) for k in folds[0]}\n",
    "    print(f\" {model_name}: \" + \", \".join([f\"{k}: {v:.4f}\" for k, v in avg.items()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeace609",
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression: Accuracy: 0.5968, F1: 0.5639, Recall: 0.6603, Specificity: 0.5553, AUROC: 0.6514\n",
    " RandomForest: Accuracy: 0.5746, F1: 0.3480, Recall: 0.3060, Specificity: 0.7489, AUROC: 0.5858\n",
    " XGBoost: Accuracy: 0.5968, F1: 0.4617, Recall: 0.4517, Specificity: 0.6911, AUROC: 0.6042\n",
    " SVM: Accuracy: 0.6349, F1: 0.5840, Recall: 0.6447, Specificity: 0.6286, AUROC: 0.6501\n",
    " LightGBM: Accuracy: 0.5778, F1: 0.4734, Recall: 0.4843, Specificity: 0.6387, AUROC: 0.5941\n",
    " NaiveBayes: Accuracy: 0.5778, F1: 0.4417, Recall: 0.4510, Specificity: 0.6596, AUROC: 0.5943"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838cf032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Build param grid\n",
    "param_grid = [\n",
    "    {\n",
    "        'penalty': ['l1'],\n",
    "        'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10],\n",
    "        'solver': ['liblinear'],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l2'],\n",
    "        'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 2, 5, 10],\n",
    "        'solver': ['liblinear', 'lbfgs'],\n",
    "        'class_weight': ['balanced']\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [0.01, 0.1, 1, 5],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [0.1, 0.5, 0.7, 0.9],\n",
    "        'class_weight': ['balanced']\n",
    "    }\n",
    "]\n",
    "\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Grid search with cross-validation\n",
    "log_cv = GridSearchCV(\n",
    "    logreg,\n",
    "    param_grid,\n",
    "    scoring='f1',       # Or 'accuracy' if that's your main target\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fit\n",
    "log_cv.fit(X_pca, y)\n",
    "\n",
    "# Output best model and params\n",
    "print(\"Best parameters:\", log_cv.best_params_)\n",
    "print(\"Best F1 score:\", log_cv.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56aeaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_cv = GridSearchCV(rf, rf_grid, scoring='f1', cv=5)\n",
    "rf_cv.fit(X_pca, y)\n",
    "\n",
    "print(\"Best Random Forest params:\", rf_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584554b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(scale_pos_weight=191/124, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_cv = GridSearchCV(xgb, xgb_grid, scoring='f1', cv=5)\n",
    "xgb_cv.fit(X_pca, y)\n",
    "\n",
    "print(\"Best XGBoost params:\", xgb_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41242dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svm_params = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'kernel': ['linear'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm_cv = GridSearchCV(svm, svm_params, scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "svm_cv.fit(X_pca, y)\n",
    "print(\"Best SVM params:\", svm_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "lgbm = LGBMClassifier(random_state=42)\n",
    "lgbm_cv = GridSearchCV(lgbm, lgbm_params, scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "lgbm_cv.fit(X_pca, y)\n",
    "print(\"Best LGBM params:\", lgbm_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2774928",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb_params = {\n",
    "    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]\n",
    "}\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb_cv = GridSearchCV(nb, nb_params, scoring='f1', cv=5, n_jobs=-1, verbose=2)\n",
    "nb_cv.fit(X_pca, y)\n",
    "print(\"Best Naive Bayes params:\", nb_cv.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec1ecf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
